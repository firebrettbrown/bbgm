{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import scipy.stats\n",
    "import scipy.optimize\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata = pd.read_csv('finviz.csv').set_index('Company')\n",
    "fdata = fdata.drop('No.',1)\n",
    "fdata.sort_values('Market Cap',0,False)\n",
    "#fdata = fdata.iloc[:,4:-1]\n",
    "fdata = fdata._get_numeric_data().fillna(0)\n",
    "fdata = fdata[fdata['Market Cap'] > 1.7e3]\n",
    "fdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('avg_stats.csv')#pd.read_csv('BBGM_League_7_all_seasons_Average_Stats.csv')\n",
    "df = df[(df.G*df.MP > 48)]\n",
    "df.shape\n",
    "#df = df.sample(10000)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:,-15:]\n",
    "X = df.iloc[:,11:-17]\n",
    "#y = y[(X['AST%'] >0) & (X['AST%'] < 100)]\n",
    "print(X.shape)\n",
    "#X = X[(X['AST%'] >0) & (X['AST%'] < 100)]\n",
    "print(X.shape)\n",
    "\n",
    "X['MP'] = df.MP\n",
    "X['Hgt'] = df['Hgt']\n",
    "\n",
    "stat_list = ['FG','FGA','3P',\"3PA\",'FT','FTA',\\\n",
    "             'ORB','DRB','TRB','AST','TOV','STL',\"Blk\",\\\n",
    "             'PF','PTS']\n",
    "for name in stat_list:\n",
    "    den = np.maximum(1,df.MP)\n",
    "    X[name + 'p36'] = 36* df[name]/den\n",
    "    X[name + 'p100'] = X[name + 'p36']*4/3\n",
    "\n",
    "\n",
    "X['PTSp36'] -= X['3Pp36']\n",
    "\n",
    "#else:\n",
    "#X['PER'] = df['PER']\n",
    "    #X['DREO'] = X['PTSp100'] + .2*X['TRBp100'] + .5*X['ASTp100'] - .9*X['FGAp100'] - .35*X['FTAp100']-6.23\n",
    "#X['PassP'] = ((X['ASTp100']-(0.38*X['Creation']))*0.752+ X['Creation'] + X['TOVp100']) ** 0.67\n",
    "#'OPM','DPM','cTOV','Load'#stat_list[:-2]+\n",
    "#'PER','FG%','DREO'\n",
    "\n",
    "\n",
    "\n",
    "X = X[[_ for _ in X.columns if '%A' in _ or _[-1]=='r' or \"+/-\" in _ or 'p36' in _ or _ in (['OSPM','DRE','OPM','BPM','DPM','Creation','cTOV','Load','Age','MP'])]]\n",
    "if True:\n",
    "    X = X[[_ for _ in X.columns if not '3P' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'Rim' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'Post' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'Mid' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'TOV' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'Blk' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'ORB' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'DRB' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'STL' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'DPM' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'OPM' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'BPM' in _]]\n",
    "    X = X[[_ for _ in X.columns if not '+/-' in _]]\n",
    "\n",
    "\n",
    "#X = X[[_ for _ in X.columns if not '3PAr' in _]]\n",
    "\n",
    "replacement_filter = (df.Salary > 0.5) & (df.Salary < 1.0)\n",
    "replacement_player_mean_bs = X[replacement_filter].mean()\n",
    "replacement_player_std_bs = X[replacement_filter].std()\n",
    "replacement_player_cov_bs = X[replacement_filter].cov()\n",
    "\n",
    "replacement_player_mean_r = y[replacement_filter].mean()\n",
    "replacement_player_std_r = y[replacement_filter].std()\n",
    "replacement_player_cov_r = y[replacement_filter].cov()\n",
    "\n",
    "\n",
    "replacement_player_mean_r\n",
    "\n",
    "X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neural_network\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import feature_selection, model_selection\n",
    "from sklearn import  multioutput\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "fexp = preprocessing.PolynomialFeatures(degree=2,interaction_only=False)\n",
    "scalerX = preprocessing.RobustScaler()\n",
    "scalery = preprocessing.StandardScaler()\n",
    "prescale_X = scalerX.fit_transform(X)\n",
    "prescale_y = scalery.fit_transform(y)\n",
    "prescale_X = fexp.fit_transform(prescale_X)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(prescale_X, prescale_y, test_size=0.25, random_state=42)\n",
    "trials = 1\n",
    "ts = []\n",
    "for i in range(trials):\n",
    "    #clf = neural_network.MLPRegressor((36,5,24,36),'tanh',solver='adam',max_iter=1000)\n",
    "    #clf = neural_network.MLPRegressor((),'identity',solver='lbfgs',alpha=5e2,tol=1e-9)\n",
    "    #clf = multioutput.MultiOutputRegressor(linear_model.SGDRegressor(penalty='l2',alpha=5e2,eta0=1e-6,tol=1e-12,max_iter=50,verbose=True))\n",
    "    clf = multioutput.MultiOutputRegressor(linear_model.ElasticNet(alpha=5e-3,l1_ratio=0.5))\n",
    "    #clf = ensemble.ExtraTreesRegressor(8,criterion='mae',max_depth=3,verbose=1)\n",
    "    #clf = multioutput.MultiOutputRegressor(svm.SVR())\n",
    "    #clf.fit(X_train,y_train)\n",
    "    #print(clf.score(X_train,y_train),clf.score(X_test,y_test))\n",
    "    clf.fit(prescale_X,prescale_y)\n",
    "    yt = scalery.inverse_transform(clf.predict(prescale_X))\n",
    "    err = np.linalg.norm(yt-y)\n",
    "    ts.append((err,clf))\n",
    "ts = sorted(ts)[::1] # why not the biggest error\n",
    "print(ts[0][0])\n",
    "clf = ts[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_keys = [_.lower() for _ in y.columns]\n",
    "\n",
    "y_map = { 'hgt': 'hgt',\n",
    "   'stre': 'str',\n",
    "   'spd': 'spd',\n",
    "   'jmp': 'jmp',\n",
    "   'endu': 'end',\n",
    "   'ins': 'ins',\n",
    "   'dnk': 'dnk',\n",
    "   'ft': 'ft.1',\n",
    "   'fg': '2pt',\n",
    "   'tp': '3pt',\n",
    "   'diq': 'diq',\n",
    "   'oiq': 'oiq',\n",
    "   'drb': 'drb',\n",
    "   'pss': 'pss',\n",
    "   'reb': 'reb' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdataV = fdata.iloc[:,1:-2]\n",
    "len(fdataV.columns),len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_obj(x):\n",
    "    x_ord = np.argsort(x)\n",
    "    inv_lookup = {v: _ for v,_ in zip(X.columns,x_ord[:len(fdataV.columns)])}\n",
    "    player_vectors = []\n",
    "    player_names = []\n",
    "    for i,row in enumerate(fdataV.itertuples()):\n",
    "        player_vectors.append([row[inv_lookup[stat]+1] for stat in X.columns])\n",
    "        player_names.append(row[0])\n",
    "    Xn = np.nan_to_num(np.array(player_vectors))\n",
    "    scalerX2 = preprocessing.RobustScaler()#quantile_range=(30.0, 70.0))\n",
    "    scalerX2.fit(Xn)\n",
    "    Xn_s =scalerX2.transform(np.nan_to_num(Xn))\n",
    "    Xn_fs = fexp.transform(np.nan_to_num(Xn_s))\n",
    "    predict = clf.predict(Xn_fs)\n",
    "    ratings = np.nan_to_num(scalery.inverse_transform(predict))\n",
    "    nc2 = np.array([5,1,4,2,1,1,2,1,1,3,7,3,3,3,1])/38\n",
    "    ovr = np.clip(ratings,0,100) @ nc2\n",
    "    return -scipy.stats.pearsonr(ovr,fdata['Market Cap'])[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_x = np.random.rand(len(fdataV.columns))\n",
    "best_v = map_obj(best_x)\n",
    "for i in range(1000):\n",
    "    x = np.random.rand(len(fdataV.columns))\n",
    "    v = map_obj(x)\n",
    "    if v < best_v:\n",
    "        best_x = x\n",
    "        best_v = v\n",
    "        print(best_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ord = np.argsort(best_x)\n",
    "inv_lookup = {v: _ for v,_ in zip(X.columns,x_ord[:len(stat_lookup)])}\n",
    "inv_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:fdataV.columns[v] for k,v in inv_lookup.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_vectors = []\n",
    "player_names = []\n",
    "for i,row in enumerate(fdataV.itertuples()):\n",
    "    player_vectors.append([row[inv_lookup[stat]+1] for stat in X.columns])\n",
    "    player_names.append(row[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn = np.nan_to_num(np.array(player_vectors))\n",
    "scalerX2 = preprocessing.RobustScaler()#quantile_range=(30.0, 70.0))\n",
    "scalerX2.fit(Xn)\n",
    "Xn_s =scalerX2.transform(np.nan_to_num(Xn))\n",
    "Xn_fs = fexp.transform(np.nan_to_num(Xn_s))\n",
    "predict = clf.predict(Xn_fs)\n",
    "ratings = np.nan_to_num(scalery.inverse_transform(predict))\n",
    "nc2 = np.array([5,1,4,2,1,1,2,1,1,3,7,3,3,3,1])/38\n",
    "ovr = np.clip(ratings,0,100) @ nc2\n",
    "#YEAR = np.clip(ratings,0,100) @ np.\n",
    "\n",
    "top_n = 30*15\n",
    "top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_active = np.zeros(ratings.shape[0])\n",
    "is_active[:top_n] = 1\n",
    "teamID = sum([[i]*15 for i in range(30)],[])\n",
    "random.shuffle(teamID)\n",
    "random.shuffle(is_active)\n",
    "len(teamID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "players = []\n",
    "tp = 0\n",
    "for name,rating,ia in zip(player_names,ratings,is_active):\n",
    "    sname = name.split(' ')\n",
    "    new_player = {}\n",
    "    new_player['firstName'] = sname[0]@\n",
    "    new_player['lastName'] = ' '.join(sname[1:])\n",
    "    \n",
    "    r_vec = {k: rating[y_keys.index(km)] for k,km in y_map.items()}\n",
    "    r_vec = {k: int(np.clip(v,0,100)) for k,v in r_vec.items()}\n",
    "\n",
    "    new_player['ratings'] = [r_vec]\n",
    "    new_player['born'] = {'year':2019-25,'loc':''}\n",
    "\n",
    "    if ia == 1:\n",
    "        new_player['tid'] = teamID[tp]\n",
    "        tp += 1\n",
    "    else:\n",
    "        new_player['tid'] = -2\n",
    "        year = np.random.randint(1,11)\n",
    "        new_player['born']['year'] += year\n",
    "        new_player['draft'] = {'year':2018+year,\"round\": 0, \"pick\": 0, \"tid\": -1, \"originalTid\": -1}\n",
    "    players.append(new_player)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(player_names),len(players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = json.load(open('league_blank.json','rb'))\n",
    "base['version'] = 33\n",
    "del base['meta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base['players'] = players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stock_{}.json'.format('roster'),'wt') as fp:\n",
    "    json.dump(base,fp, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
